<head>
        <link rel="stylesheet" href="assets/style.css">

</head>
<h2>Assumption-Driven Design and the Case for Studying Human-Model and Model-Model Interaction</h2>
<p>
<i>Started writing: 3/13/2025</i>
</p>
<br>
<hr>
<br>
<p>
For decades, UX research has shaped how we design technology to fit human needs, with Human-Computer Interaction (HCI) leading the way as a dominant framework. 
As AI systems are deployed across more industries and embedded into daily workflows, the user is becoming overlooked. 
Traditional UX research has ensured that technology directly aligns with human needs. 
But in AI development, the user-centric approach is eroding. 
Models are being designed based on developer assumptions rather than real-world needfinding, leading to solutions that waste significant resources while providing little return compared to the alternative process. 
If custom models are to provide real value, we need a focused shift toward human-model interaction, which can be presented as an approach that prioritizes usability and user impact throughout the entire design cycle. 
</p>
<br>
<p>
Non-Human Identities (NHIs) such as service accounts, middleware, background services, and automated bots have long operated without interfaces explicitly designed for human interaction. 
Because these systems primarily interacted with other machines, there was little need for a dedicated discipline of “NHI design” in the way HCI developed for human users. 
AI models extend this lineage of NHIs but differ in the way that their outputs increasingly shape human decisions while remaining opaque. 
This abstraction, or lack of explainability, reveals a gap in usability research that current UX methodologies fail to address. 
While HCI principles emphasize user engagement, AI-driven systems require a parallel framework that accounts for model interpretability, decision latency, and mechanisms for updating decisions based on evolving conditions. 
Without these considerations, we risk deploying models that reinforce biases, misalign with user workflows, and ultimately deliver minimal ROI despite significant computational and development costs. 
Human-Model Interaction (HMI) must evolve as a distinct discipline so that AI systems are not just technically proficient but also operationally effective.

</p>
<br>
<p>
If HMI ensures that AI systems remain aligned with human needs, I propose the next frontier as Model-Model Interaction (MMI), which is how AI systems interact with each other autonomously. 
As AI agents become more independent, collaborating, negotiating, and even conflicting without human oversight, we need new frameworks to keep these interactions efficient and interpretable while remaining accountable to human priorities. 
Without careful design, agentic AI risks amplifying emergent behaviors that are unpredictable or even adversarial. 
The idea of being guided by clearly defined human intentions is not new, as Human-in-the-Middle frameworks have long aimed to keep AI systems aligned with human needs. 
Were Model-Model Interaction a formal area of study, it would seek to answer the question: How do we regulate, optimize, and govern systems that increasingly communicate and make decisions without us?
</p>

