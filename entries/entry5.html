<head>
        <link rel="stylesheet" href="assets/style.css">

</head>


<h2>Why your Bottleneck is Defining of your Entire Environment</h2>
<p>
<i>Started writing: 2/18/2025</i>
</p>
<br>
<hr>
<br>

<p>
I truly believe that divide-and-conquer isn’t just an algorithmic strategy constrained by theory. It can be extended into how we approach complex problems in business, cybersecurity, and with any decision-making. 
Yet, I’ve heard countless computer science graduates say, “I couldn’t learn advanced DSA, so I went into cybersecurity/UX design/data analysis/IT administration.” 
But here’s the thing: if you work in any field that requires structured problem-solving, you already use these concepts. 
You just might not realize it yet, or label those concepts as such.


</p>
<br>
<p>
    In complexity theory, specifically in algorithm analysis, the total time complexity of a process is dictated by its dominating factor—the part of the system that takes the longest. 
    No matter how well you optimize one subproblem, if another step is significantly slower, it will dictate the overall efficiency. 
    This concept is formally known as asymptotic analysis, which describes the limiting behavior of a function when the argument tends toward a particular value or infinity. 
</p>
<br>
<p>
        To put it through the lens of Product Management (specifically the manufacturing part), think of it like a production line: if one stage of assembly takes twice as long as the others, improving the speed of every other step won’t make the process any faster overall. 
    The slowest part will always determine the pace over the long term, or many iterations of performing a process. 
    A bottleneck is the single point in a process that limits the overall output. 
    It is the piece that, when ignored, renders all other improvements ineffective. 

</p>
<br>
<br>
<p>
    <u>Why Minor Optimizations Often Fail at Scale</u>
</p>
<p>
    Companies break down massive goals into smaller, more manageable parts all the time. Whether launching a product or securing a large network, the work is divided into subproblems, just like in divide-and-conquer algorithms. But many organizations go about the strategy wrong, as they take a long time optimizing individual areas without considering the overall impact. 

</p>
<br>
<p>
    Take incident response as an example. 
    If detection takes milliseconds but escalation decisioning takes hours, the speed of detection becomes irrelevant. 
    The time complexity of the whole process isn’t determined by the fastest part, it’s dictated by the slowest. 
    And in the long run, that slowest part will define the organization’s entire process ability to respond effectively. 

</p>

<br>
<p>
    Similarly, in business operations, companies often focus on streamlining the workflows of specific departments without addressing the true source of inefficiency. 
    Automating part of a workflow won’t significantly improve overall productivity if another step in the chain remains extremely slow. 
    This is a classic example of confusing local optimization with global optimization. 

</p>
<br>
<p>
    But why do businesses often justify focusing on local optimization? 
    This may happen because addressing the true bottleneck is a complex and resource-intensive endeavor. 
    This approach may be logical in the short term, but it is fundamentally flawed. 
    The most common reason they use to ignore the bottleneck is that it requires significant capital, time, and human resources that an organization might not have <strong>all at once</strong>. 
    It’s far easier and cheaper to automate a small, specific task within a single department. Additionally, it may be due to perceived efficiency gains. 
    Managers and teams are often heavily incentivized by departmental metrics. Automating a workflow in their own department provides this measurable increase in their own productivity, even if it has no impact on the company’s overall output. 
    This creates a false sense of progress. Addressing the fear of disruption is another one. 
    Fixing a major bottleneck can disrupt the entire organization. 
    It may require re-training many employees and changing established business models, where companies may prefer to work around the edges to avoid this upheaval. 
    And then there’s the lack of visibility.
    Many times, the bottleneck is not obvious. 
    Without proper Product Management principles in place (cross-functional collaboration being the one referenced here), departments operate in silos, with their individual managers lacking a clear view of the end-to-end process. 
    They may not even realize their “efficient” department is just creating a bigger pile-up for the next step in the chain. 

</p>

<br>
<p>
    In the next section, I will address how to strategically tackle the bottleneck even with limited resources.

</p>
<br>
<br>
<p><u>Taking a Focused Approach to Problem-Solving Overall</u></p>
<p>
    If you understand time complexity, you understand how to prioritize strategically. 
    Don’t just break a problem into subproblems and start tackling them individually. 
    Prioritizing the wrong subproblem can lead to wasted effort and minimal impact, while addressing the most time-consuming or resource-intensive step can improve your workflow most significantly. 

</p>
<br>
<p>
    Breaking problems into smaller parts is useful, but breaking them down strategically is what turns simple reasoning into meaningful problem-solving. 
    A focused approach requires discipline, meaning resisting the temptation to optimize areas that are already functioning well simply because they are easier to measure or more visible. 
    True improvement comes from identifying the heavy system constraints and also requires iterative assessment as bottlenecks are tricky and shift over time as solutions are applied. 

</p>
<br>
<p>
    You don’t want to use resources to continuously patch only symptoms of the weakest part of the system that governs outcomes. 
    While the bottleneck is often a major, resource-intensive challenge, it’s a common misconception that addressing it is always a matter of significant financial investment. 
    You may find that it’s about changing a process or policy. 
    In this case, a company can address a “bureaucratic bottleneck” by mapping out the entire approval process using the existing governance documents that link together across departments and functions, identify the unnecessary or duplicate steps, and work with stakeholders to eliminate them. 
    This doesn’t necessarily require a large budget, however, it will require organizational capital. 
    And many large companies already have allocated resources for this, such as for process improvement or quality assurance functions.

</p>
<br>
<br>
<p><u>You Are Only as Strong as Your Weakest Link</u></p>
<p>
    When organizations or individuals ignore their bottleneck, they risk creating an illusion of progress. 
    The reality is that until the slowest, least efficient part of the process improves, the overall system won’t meaningfully change. 
    You may actually be wasting resources, because celebrating small optimizations can leave the real constraint completely ignored. 
    The goal is to make efforts that have greater impact using fewer resources, as is the goal for many “lean” functions. 
    Lean philosophy emphasizes identifying value-creating activities, eliminating waste, and continuous improvement of people and processes. 
    Lean thinking verifies that every effort directly contributes to overall system efficiency rather than optimizing components in isolation. 
    Lean naturally points us toward the true bottlenecks in a system, so it’s wise to start there.

</p>
<br>
<p>
    The biggest mistake people make in understanding the divide-and-conquer approach is assuming it is simply about “splitting problems apart.” 
    It is much more about knowing which piece to conquer first. 
    The order of attack matters just as much as the act of division itself. 
    The art of sequencing is no different in cybersecurity. You are still looking at the problem as a whole rather than optimizing individual components, as divide doesn’t mean ignore. 
    The misconception stems from a fundamental misunderstanding of the “conquer” part of the algorithm. 
    That is where the concept of synergy comes in. The sum of the parts is not always the sum of the whole. 
    In a well-executed divide-and-conquer strategy, the way in which you solve one piece can dramatically reduce the effort required to solve the others.

</p>
<br>
<br>

<p><u>Synergy and Prioritization</u></p>
<p>
    Consider the classic example of Merge Sort. 
    The “divide” phase is simple: you repeatedly split the list in half. 
    But looking to the “conquer” phase, you merge the sorted sub-lists. 
    The most important insight here is that by ensuring each small list is sorted first, the subsequent merging process is incredibly efficient. 
    If you tried to merge unsorted lists, you’d be back to the original problem. 
    Sort the small pieces first to make the larger task of merging trivial. 

</p>
<br>
<p>
    The “divide-and-ignore” mistake can be compared to a security team that finds a hundred vulnerabilities and then assigns each one to a different engineer to patch, with no regard for dependencies. 
    Let’s look at an example of a true “divide-and-conquer” approach for this scenario instead:

</p>
<br>
<p>
<ol>
    <li><strong>Prioritization:</strong> The team would identify which vulnerabilities are “gateway” vulnerabilities, or those that, if exploited, provide access to a host of other systems or data. 
        Conquering this one piece first might neutralize a dozen other potential attack vectors.
</li>
<li><strong>Chaining</strong>: Most attackers never look at systems as a set of isolated vulnerabilities, rather, they think in terms of exploit chains. 
    They find one vulnerability which they conquer to chain additional pieces with each step being a prerequisite for the next. 
    This is why planned sequences of attack are now a part of modern cyber defense frameworks like MITRE ATT&CK, being mapped out, tracked, and studied by security researchers.
</li>
</ol>
</p>
<br>
<p>
    A mistake here would be failing to recognize the interdependencies and casual relationships between the sub-problems you are working with once you “divide.” 
    You want to focus on which parts, when solved first, will yield the greatest return and make the entire problem simpler to solve. 
    The strategy is about optimizing the whole by addressing the components, but never overlooking how they fit together. 

</p>
<br>
<br>
<p>
    <u>Concluding How to Conquer What Matters</u>

</p>
<p>
    Divide-and-conquer in practice holds a real power in teaching us to recognize where effort matters the most. 
    Problems will always exist in parts, but not all parts are equal in influence. 
    You must then choose the correct sequence, focus on the constraint, and order the execution appropriately. 
    This reflects an elevated and mature level of critical thought. 

</p>
<br>
<p>
    This is as true in cybersecurity as it is in business as large. 
    You are not defined by your strongest controls, rather, by the part of your environment that slows you down. 
    To refer to the familiar principle of disruption— if you don’t disrupt yourself, the market will eventually do it for you. 

</p>

<br>
<p>
    Ultimately, you can design your operations however you want, and you can run your programs however you want. 
    But I choose to know my weaknesses, to confront them, and to continually address them, because they are what will ultimately dictate my trajectory, whether I’m aware of it or not. 

</p>